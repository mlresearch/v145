---
title: Reduced Order Modeling using Shallow ReLU Networks with Grassmann Layers
abstract: 'This paper presents a nonlinear model reduction method for systems of equations
  using a structured neural network. The neural network takes the form of a “three-layer”
  network with the first layer constrained to lie on the Grassmann manifold and the
  first activation function set to identity, while the remaining network is a standard
  two-layer ReLU neural network. The Grassmann layer deter- mines the reduced basis
  for the input space, while the remaining layers approximate the nonlinear input-output
  system. The training alternates between learning the reduced basis and the nonlin-
  ear approximation, and is shown to be more effective than fixing the reduced basis
  and training the network only. An additional benefit of this approach is, for data
  that lie on low-dimensional subspaces, that the number of parameters in the network
  does not need to be large. We show that our method can be applied to scientific
  problems in the data-scarce regime, which is typically not well-suited for neural
  networks approximations. Examples include reduced order modeling for nonlinear dynamical
  systems and several aerospace engineering problems. '
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bollinger22a
month: 0
tex_title: Reduced Order Modeling using Shallow ReLU Networks with Grassmann Layers
firstpage: 847
lastpage: 867
page: 847-867
order: 847
cycles: false
bibtex_author: Bollinger, Kayla and Schaeffer, Hayden
author:
- given: Kayla
  family: Bollinger
- given: Hayden
  family: Schaeffer
date: 2022-04-30
address:
container-title: Proceedings of the 2nd Mathematical and Scientific Machine Learning
  Conference
volume: '145'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 4
  - 30
pdf: https://proceedings.mlr.press/v145/bollinger22a/bollinger22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
