---
title: 'Borrowing From the Future: Addressing Double Sampling in Model-free Control'
abstract: 'In model-free reinforcement learning, the temporal difference method is
  an important algorithm but might become unstable when combined with nonlinear function
  approximations. Bellman residual minimization with stochastic gradient descent (SGD)
  is stable but suffers from the double sampling problem: given the current state,
  two independent samples for the next state are required, but often only one sample
  is available. Recently, the borrowing-from-the-future (BFF) algorithm was intro-
  duced in (Zhu et al., 2020) to address this issue for policy evaluation. The main
  idea is to borrow extra randomness from the future to approximately re-sample the
  next state when the underlying dynamics of the problem are sufficiently smooth.
  This paper extends the BFF algorithm to action- value function based model-free
  control. We prove that BFF is close to unbiased SGD when the underlying dynamics
  vary slowly with respect to actions. We confirm our theoretical findings with numerical
  simulations. '
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhu22a
month: 0
tex_title: 'Borrowing From the Future: Addressing Double Sampling in Model-free Control'
firstpage: 1099
lastpage: 1136
page: 1099-1136
order: 1099
cycles: false
bibtex_author: Zhu, Yuhua and Izzo, Zachary and Ying, Lexing
author:
- given: Yuhua
  family: Zhu
- given: Zachary
  family: Izzo
- given: Lexing
  family: Ying
date: 2022-04-30
address:
container-title: Proceedings of the 2nd Mathematical and Scientific Machine Learning
  Conference
volume: '145'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 4
  - 30
pdf: https://proceedings.mlr.press/v145/zhu22a/zhu22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
