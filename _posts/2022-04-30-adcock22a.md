---
title: Deep Neural Networks Are Effective At Learning High-Dimensional Hilbert-Valued
  Functions From Limited Data
abstract: 'The accurate approximation of scalar-valued functions from sample points
  is a key task in mathematical modelling and computational science. Recently, machine
  learning techniques based on Deep Neural Networks (DNNs) have begun to emerge as
  promising tools for function approximation in scientific computing problems, with
  some impressive results achieved on problems where the dimension of the underlying
  data or problem domain is large. In this work, we broaden this perspective by focusing
  on the approximation of functions that are \textit{Hilbert-valued}, i.e. they take
  values in a separable, but typically infinite-dimensional, Hilbert space. This problem
  arises in many science and engineering problems, in particular those involving the
  solution of parametric Partial Differential Equations (PDEs). Such problems are
  challenging for three reasons. First, pointwise samples are expensive to acquire.
  Second, the domain of the function is usually high dimensional, and third, the range
  lies in a Hilbert space. Our contributions are twofold. First, we present a novel
  result on DNN training for holomorphic functions with so-called \textit{hidden anisotropy}.
  This result introduces a DNN training procedure and a full theoretical analysis
  with explicit guarantees on the error and sample complexity. This error bound is
  explicit in the three key errors occurred in the approximation procedure: the best
  approximation error, the measurement error and the physical discretization error.
  Our result shows that there exists a procedure (albeit a non-standard one) for learning
  Hilbert-valued functions via DNNs that performs as well as, but no better than current
  best-in-class schemes. It therefore gives a benchmark lower bound for how well methods
  DNN training can perform on such problems. Second, we examine whether better performance
  can be achieved in practice through different types of architectures and training.
  We provide preliminary numerical results illustrating the practical performance
  of DNNs on Hilbert-valued functions arising as solutions to parametric PDEs. We
  consider different parameters, modify the DNN architecture to achieve better and
  competitive results and compare these to current best-in-class schemes. '
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: adcock22a
month: 0
tex_title: Deep Neural Networks Are Effective At Learning High-Dimensional Hilbert-Valued
  Functions From Limited Data
firstpage: 1
lastpage: 36
page: 1-36
order: 1
cycles: false
bibtex_author: Adcock, Ben and Brugiapaglia, Simone and Dexter, Nick and Morage, Sebastian
author:
- given: Ben
  family: Adcock
- given: Simone
  family: Brugiapaglia
- given: Nick
  family: Dexter
- given: Sebastian
  family: Morage
date: 2022-04-30
address:
container-title: Proceedings of the 2nd Mathematical and Scientific Machine Learning
  Conference
volume: '145'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 4
  - 30
pdf: https://proceedings.mlr.press/v145/adcock22a/adcock22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
